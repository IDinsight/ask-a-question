# If not set, default values are loaded from core_backend/app/**/config.py files

#### ðŸ”’ Postgres variables -- change for production ###########################
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres  #pragma: allowlist secret
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=postgres

#### ðŸ”’ Admin user -- change for production ###################################
ADMIN_USERNAME="admin"
ADMIN_PASSWORD="fullaccess" #pragma: allowlist secret
ADMIN_API_KEY="admin-key"   #pragma: allowlist secret

#### Admin user rate limits ###################################################
# ADMIN_CONTENT_QUOTA=1000
# ADMIN_API_DAILY_QUOTA=100

#### ðŸ”’ JWT -- change for production ###########################################
JWT_SECRET="jwt-secret"    #pragma: allowlist secret

#### Dashboard settings #######################################################
DISABLE_DASHBOARD_LLM=False

#### Redis  -- change for production ##########################################
REDIS_HOST="redis://localhost:6379"
# For docker compose, use "redis://redis:6379"

#### LiteLLM Proxy Server -- change for production ############################
LITELLM_ENDPOINT="http://localhost:4000"
# For docker compose, use "http://litellm_proxy:4000"

#### Variables for Huggingface embeddings container ###########################
# If on ARM, you need to build the embeddings image manually using
# `make build-embeddings-arm` from repository root and set the following variables
#EMBEDDINGS_IMAGE_NAME=text-embeddings-inference-arm
#PGVECTOR_VECTOR_SIZE=1024

#### Speech APIs ###############################################################
# CUSTOM_STT_ENDPOINT=http://speech_service:8001/transcribe
# CUSTOM_TTS_ENDPOINT=http://speech_service:8001/synthesize

#### Temporary folder for prometheus gunicorn multiprocess ####################
PROMETHEUS_MULTIPROC_DIR="/tmp"

#### Application-wide content limits ##########################################
# CHECK_CONTENT_LIMIT=True
# DEFAULT_CONTENT_QUOTA=50
# PAGES_TO_CARDS_CONVERSION=2  # for DocMuncher, estimate of cards per page


#### Number of top content to return for /search. #############################
# N_TOP_CONTENT=5

#### Urgency detection variables ##############################################
# URGENCY_CLASSIFIER="cosine_distance_classifier"
# Choose between `cosine_distance_classifier` and `llm_entailment_classifier`

# URGENCY_DETECTION_MAX_DISTANCE=0.5
# Only used if URGENCY_CLASSIFIER=cosine_distance_classifier

# URGENCY_DETECTION_MIN_PROBABILITY=0.5
# Only used if URGENCY_CLASSIFIER=llm_entailment_classifier

#### LLM response alignment scoring ###########################################
# ALIGN_SCORE_THRESHOLD=0.7

#### LiteLLM tracing ##########################################################
LANGFUSE=False

# ðŸ”’ Keys
# LANGFUSE_PUBLIC_KEY="pk-..."
# LANGFUSE_SECRET_KEY="sk-..."  #pragma: allowlist secret
# Set LANGFUSE=True to enable Langfuse logging, and set the keys.
# See https://docs.litellm.ai/docs/observability/langfuse_integration for more
# information.

# Optional based on your Langfuse host:
# LANGFUSE_HOST="https://cloud.langfuse.com"

##### Google Cloud Storage Variables#############################################
# GCS_SPEECH_BUCKET="aaq-speech-test"
# Set this variable up to your specific GCS bucket for storage and retrieval for Speech Workflow.

#### Sentry ###################################################################
SENTRY_DSN="https://..."

#### Document ingestion variables ###############################################
MISTRAL_API_KEY =
