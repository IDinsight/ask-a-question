# Deploying and Using Custom embeddings

To host huggingface embeddings we are using the
[text-embeddings-inference](https://github.com/huggingface/text-embeddings-inference)
by huggingface

## How to deploy

Before deploying custom, we need to make sure that the vector size generated by the new
embeddings is the same as pgvector vector size in `PGVECTOR_VECTOR_SIZE`. If not, we can
update the vector size by uncommenting it in `.core_backend.env` and updating it to the new
value. Note that if the database is already existing, this will not work unless the database is
destroyed and created again.

To deploy custom embeddings, follow the deployment instructions in [Quick Setup]("../../deployment/quick-setup.md").

On **Step 4:**:

1. Edit `.litellm_proxy.env` by uncommenting `HUGGINGFACE_MODEL`, `CUSTOM_EMBEDDINGS_API_KEY`
   and `CUSTOM_EMBEDDINGS_ENDPOINT`. `HUGGINGFACE_MODEL` and `CUSTOM_EMBEDDINGS_API_KEY` and
   should be updated accordin to need, but the default `CUSTOM_EMBEDDINGS_ENDPOINT` should
   work with docker compose.
2. Update `litellm_proxy_config.yaml` by uncommenting the second embeddings model:
   ```
   # - model_name: embeddings
   #   litellm_params:
   #     model: huggingface/custom_embeddings # model name not important
   #     api_key: "os.environ/CUSTOM_EMBEDDINGS_API_KEY" #pragma: allowlist secret
   #     api_base: "os.environ/CUSTOM_EMBEDDINGS_ENDPOINT"
   ```
   The first embeddings model should be commented out unless using custom embeddings
   as a back up to openai embeddings.

---

**Note**

If using an arm64 device, a docker image should be built locally before deployment.
This can be done by running the make command: `make build-embeddings-arm`. Also,
the variable `EMBEDDINGS_IMAGE_NAME` should be uncommented in `.core_backend.env`

---

On **Step 6:** _Run docker-compose_, run the following command instead:

```bash
docker compose -f docker-compose.yml -f docker-compose.dev.yml \
    --profile local-embeddings -p aaq-stack up -d --build
```

### Dev setup

If you are using the [Dev setup](../../develop/setup.md), you can start the container
manually using:

```bash
make setup-embeddings
```

If you are using an arm device, you can first build the image using:

```bash
make build-embeddings-arm
```

then:

```bash
make build-embeddings-arm
```

---

**Note**

Before running the commands above, you need to make sure to export the environment variables
`HUGGINGFACE_MODEL` and `CUSTOM_EMBEDDINGS_API_KEY` by using:

```bash
export HUGGINGFACE_MODEL=<add-model-name>
export CUSTOM_EMBEDDINGS_API_KEY=<add-token>
```

The embeddings api endpoint by default is at: http://localhost:8080.

---

## Also see

1. [Quick Setup]("../../deployment/quick-setup.md")
2. [Configuring AAQ]("../../deployment/config-options.md")
